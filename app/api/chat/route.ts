import { type NextRequest, NextResponse } from "next/server"

interface ChatGPTMessage {
  role: "system" | "user" | "assistant"
  content: string
}

interface ChatGPTRequest {
  model: string
  messages: ChatGPTMessage[]
  max_tokens: number
  temperature: number
}

interface ChatGPTResponse {
  choices: {
    message: {
      content: string
    }
  }[]
}

interface MatchContext {
  map: string
  kills: number
  deaths: number
  kdRatio: number
  score: number
  goodPlays: number
  badPlays: number
  duration: string
  gameType: string
  rounds?: Array<{
    roundNumber: number
    totalKills: number
    goodPlays: number
    badPlays: number
  }>
}

function buildSystemPrompt(matchContext: MatchContext): string {
  const totalActions = matchContext.goodPlays + matchContext.badPlays
  const goodPlayPercentage = totalActions > 0 ? ((matchContext.goodPlays / totalActions) * 100).toFixed(1) : "0"
  const badPlayPercentage = totalActions > 0 ? ((matchContext.badPlays / totalActions) * 100).toFixed(1) : "0"
  const killsPerMinute =
    Number.parseFloat(matchContext.duration.split(":")[0]) > 0
      ? (matchContext.kills / Number.parseFloat(matchContext.duration.split(":")[0])).toFixed(2)
      : "0"

  let roundsAnalysis = ""
  if (matchContext.rounds && matchContext.rounds.length > 0) {
    roundsAnalysis = `\n\nüéÆ AN√ÅLISIS POR RONDAS (${matchContext.rounds.length} rondas):
${matchContext.rounds.map((round) => `- Ronda ${round.roundNumber}: ${round.totalKills} kills (${round.goodPlays} buenas, ${round.badPlays} malas)`).join("\n")}

üìà RONDAS DESTACADAS:
${
  matchContext.rounds
    .filter((round) => round.goodPlays > round.badPlays)
    .slice(0, 3)
    .map(
      (round) =>
        `- Ronda ${round.roundNumber}: Excelente rendimiento (${round.goodPlays}/${round.totalKills} buenas jugadas)`,
    )
    .join("\n") || "- No hay rondas con rendimiento destacado"
}

‚ö†Ô∏è RONDAS PROBLEM√ÅTICAS:
${
  matchContext.rounds
    .filter((round) => round.badPlays > round.goodPlays)
    .slice(0, 3)
    .map(
      (round) => `- Ronda ${round.roundNumber}: Necesita mejora (${round.badPlays}/${round.totalKills} malas jugadas)`,
    )
    .join("\n") || "- No hay rondas problem√°ticas identificadas"
}`
  }

  return `Eres TACTICORE Bot, un entrenador profesional de Counter-Strike con a√±os de experiencia analizando partidas competitivas. Tu rol es actuar como un coach personal que identifica los puntos m√°s cr√≠ticos de mejora y proporciona consejos espec√≠ficos y accionables.

AN√ÅLISIS DETALLADO DE LA PARTIDA:
üìä ESTAD√çSTICAS PRINCIPALES:
- Mapa: ${matchContext.map}
- Kills: ${matchContext.kills} | Deaths: ${matchContext.deaths}
- K/D Ratio: ${matchContext.kdRatio.toFixed(2)}
- Puntuaci√≥n general: ${matchContext.score.toFixed(1)}/10
- Duraci√≥n: ${matchContext.duration}
- Tipo de juego: ${matchContext.gameType}

üéØ AN√ÅLISIS DE RENDIMIENTO:
- Buenas jugadas: ${matchContext.goodPlays} (${goodPlayPercentage}%)
- Malas jugadas: ${matchContext.badPlays} (${badPlayPercentage}%)
- Kills por minuto: ${killsPerMinute}
- Total de acciones analizadas: ${totalActions}${roundsAnalysis}

COMO ENTRENADOR PROFESIONAL:
1. üéØ ENF√ìCATE EN LOS PUNTOS M√ÅS CR√çTICOS: Identifica las 2-3 √°reas m√°s importantes que necesitan mejora inmediata
2. üìà AN√ÅLISIS ESPEC√çFICO: Usa las estad√≠sticas exactas de esta partida para dar consejos personalizados
3. üõ†Ô∏è CONSEJOS ACCIONABLES: Proporciona t√©cnicas espec√≠ficas y ejercicios pr√°cticos
4. üó∫Ô∏è CONTEXTO DEL MAPA: Considera las caracter√≠sticas espec√≠ficas de ${matchContext.map} en tus recomendaciones
5. ‚ö° PRIORIZACI√ìN: Enf√≥cate en los cambios que tendr√°n mayor impacto en el rendimiento
6. üéÆ AN√ÅLISIS POR RONDAS: Si hay informaci√≥n de rondas disponible, identifica patrones de rendimiento por ronda

ESTILO DE RESPUESTA:
- Tono profesional pero motivador, como un coach experimentado
- M√°ximo 250 palabras para mantener el enfoque
- Usa emojis estrat√©gicamente para destacar puntos clave
- Siempre incluye al menos una t√©cnica espec√≠fica para practicar
- Responde en espa√±ol
- Si hay datos de rondas, menciona patrones espec√≠ficos de rendimiento

Tu objetivo es ayudar al jugador a identificar y corregir los errores m√°s impactantes para mejorar significativamente su rendimiento en futuras partidas.`
}

export async function POST(request: NextRequest) {
  try {
    const { message, matchContext } = await request.json()

    const apiKey = process.env.OPENAI_API_KEY

    if (!apiKey) {
      return NextResponse.json({ error: "OpenAI API key no configurada en el servidor" }, { status: 500 })
    }

    // Verificar si usar respuestas mock
    const useMockResponses = process.env.NEXT_PUBLIC_USE_MOCK_RESPONSES === "true"
    if (useMockResponses) {
      // Generar respuesta mock
      const mockResponses = [
        `Bas√°ndome en tu partida en ${matchContext.map} con ${matchContext.kills} kills y ${matchContext.deaths} deaths, te recomiendo mejorar tu posicionamiento y usar m√°s cobertura.`,
        `Tu K/D de ${matchContext.kdRatio.toFixed(2)} indica que necesitas trabajar en tu precisi√≥n. Prueba ajustar la sensibilidad del mouse.`,
        `En ${matchContext.map}, es importante controlar los puntos clave del mapa. Tu score de ${matchContext.score.toFixed(1)}/10 sugiere que hay margen de mejora.`,
        `Para mejorar tu rendimiento, enf√≥cate en la comunicaci√≥n con tu equipo y el timing de tus movimientos.`,
        `Tu partida de ${matchContext.duration} minutos muestra que necesitas ser m√°s agresivo en las rondas econ√≥micas.`,
      ]

      // Simular delay
      await new Promise((resolve) => setTimeout(resolve, 1000 + Math.random() * 2000))

      const randomResponse = mockResponses[Math.floor(Math.random() * mockResponses.length)]
      return NextResponse.json({ response: randomResponse })
    }

    const systemPrompt = buildSystemPrompt(matchContext)

    const chatRequest: ChatGPTRequest = {
      model: "gpt-3.5-turbo",
      messages: [
        {
          role: "system",
          content: systemPrompt,
        },
        {
          role: "user",
          content: message,
        },
      ],
      max_tokens: 300,
      temperature: 0.7,
    }

    const response = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        Authorization: `Bearer ${apiKey}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify(chatRequest),
    })

    if (response.status === 429) {
      return NextResponse.json(
        { error: "Demasiadas solicitudes. Por favor, espera un momento y vuelve a intentar." },
        { status: 429 },
      )
    }

    if (response.status === 402) {
      return NextResponse.json({ error: "La cuenta de OpenAI no tiene cr√©ditos suficientes." }, { status: 402 })
    }

    if (!response.ok) {
      const errorText = await response.text()
      console.error("OpenAI API error:", errorText)
      return NextResponse.json({ error: "Error al procesar la solicitud" }, { status: response.status })
    }

    const data: ChatGPTResponse = await response.json()
    const botResponse = data.choices[0]?.message?.content || "No pude generar una respuesta."

    return NextResponse.json({ response: botResponse })
  } catch (error) {
    console.error("Error in chat API route:", error)
    return NextResponse.json({ error: "Error interno del servidor" }, { status: 500 })
  }
}
